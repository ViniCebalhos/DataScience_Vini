{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpeza de Dados - Sistema E-Sa√∫de\n",
    "## Perfil de Atendimento Outros Profissionais de N√≠vel Superior\n",
    "\n",
    "**Projeto de P√≥s-Gradua√ß√£o**\n",
    "\n",
    "Este notebook realiza a limpeza completa dos dados, removendo valores inconsistentes, duplicatas e outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√£o das bibliotecas necess√°rias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√µes para melhor visualiza√ß√£o\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dataset consolidado (se existir) ou carrega todos os datasets\n",
    "try:\n",
    "    # Tenta carregar o dataset consolidado\n",
    "    df = pd.read_csv('Dados/dataset_consolidado_completo.csv', sep=';', encoding='utf-8')\n",
    "    print(f\"‚úì Dataset consolidado carregado: {len(df):,} registros\")\n",
    "except FileNotFoundError:\n",
    "    # Se n√£o existir, carrega todos os datasets\n",
    "    print(\"Carregando todos os datasets...\")\n",
    "    import glob\n",
    "    import os\n",
    "    \n",
    "    arquivos_csv = glob.glob('Dados/*.csv')\n",
    "    arquivos_csv = [f for f in arquivos_csv if 'Dicionario' not in f]\n",
    "    arquivos_csv.sort()\n",
    "    \n",
    "    dataframes = []\n",
    "    for arquivo in arquivos_csv:\n",
    "        nome_arquivo = os.path.basename(arquivo)\n",
    "        periodo = nome_arquivo.split('_')[0]\n",
    "        \n",
    "        df_temp = pd.read_csv(arquivo, sep=';', encoding='latin1')\n",
    "        df_temp['Periodo'] = periodo\n",
    "        dataframes.append(df_temp)\n",
    "        \n",
    "    df = pd.concat(dataframes, ignore_index=True)\n",
    "    print(f\"‚úì Dataset consolidado criado: {len(df):,} registros\")\n",
    "\n",
    "print(f\"\\nDimens√µes iniciais: {df.shape[0]:,} registros x {df.shape[1]} colunas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. An√°lise Inicial dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informa√ß√µes b√°sicas\n",
    "print(\"INFORMA√á√ïES B√ÅSICAS DOS DADOS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total de registros: {len(df):,}\")\n",
    "print(f\"Total de colunas: {df.shape[1]}\")\n",
    "print(f\"Mem√≥ria utilizada: {df.memory_usage(deep=True).sum() / (1024*1024):.1f} MB\")\n",
    "\n",
    "# Verifica√ß√£o de valores nulos\n",
    "print(f\"\\nVALORES NULOS POR COLUNA:\")\n",
    "print(\"=\" * 30)\n",
    "nulos = df.isnull().sum()\n",
    "colunas_com_nulos = nulos[nulos > 0].sort_values(ascending=False)\n",
    "\n",
    "if len(colunas_com_nulos) > 0:\n",
    "    for col, count in colunas_com_nulos.items():\n",
    "        percentual = (count / len(df)) * 100\n",
    "        print(f\"{col}: {count:,} ({percentual:.1f}%)\")\n",
    "else:\n",
    "    print(\"Nenhuma coluna com valores nulos\")\n",
    "\n",
    "# Verifica√ß√£o de valores √∫nicos\n",
    "print(f\"\\nVALORES √öNICOS POR COLUNA:\")\n",
    "print(\"=\" * 30)\n",
    "for col in df.columns:\n",
    "    n_unicos = df[col].nunique()\n",
    "    print(f\"{col}: {n_unicos:,} valores √∫nicos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Identifica√ß√£o de Problemas nos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte datas para an√°lise\n",
    "print(\"AN√ÅLISE DE DATAS\")\n",
    "print(\"=\" * 20)\n",
    "\n",
    "df['Data do Atendimento'] = pd.to_datetime(df['Data do Atendimento'], \n",
    "                                           format='%d/%m/%Y %H:%M:%S', errors='coerce')\n",
    "df['Data de Nascimento'] = pd.to_datetime(df['Data de Nascimento'], \n",
    "                                          format='%d/%m/%Y %H:%M:%S', errors='coerce')\n",
    "\n",
    "# An√°lise de datas inv√°lidas\n",
    "datas_invalidas_atendimento = df['Data do Atendimento'].isnull().sum()\n",
    "datas_invalidas_nascimento = df['Data de Nascimento'].isnull().sum()\n",
    "\n",
    "print(f\"Datas de atendimento inv√°lidas: {datas_invalidas_atendimento:,} ({datas_invalidas_atendimento/len(df)*100:.1f}%)\")\n",
    "print(f\"Datas de nascimento inv√°lidas: {datas_invalidas_nascimento:,} ({datas_invalidas_nascimento/len(df)*100:.1f}%)\")\n",
    "\n",
    "# An√°lise de datas futuras ou muito antigas\n",
    "data_atual = pd.Timestamp.now()\n",
    "data_minima = pd.Timestamp('1900-01-01')\n",
    "data_maxima = pd.Timestamp('2025-12-31')\n",
    "\n",
    "datas_futuras_atendimento = (df['Data do Atendimento'] > data_atual).sum()\n",
    "datas_muito_antigas_nascimento = (df['Data de Nascimento'] < data_minima).sum()\n",
    "datas_futuras_nascimento = (df['Data de Nascimento'] > data_atual).sum()\n",
    "\n",
    "print(f\"\\nDatas de atendimento no futuro: {datas_futuras_atendimento:,}\")\n",
    "print(f\"Datas de nascimento muito antigas (<1900): {datas_muito_antigas_nascimento:,}\")\n",
    "print(f\"Datas de nascimento no futuro: {datas_futuras_nascimento:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de idades absurdas\n",
    "print(\"AN√ÅLISE DE IDADES\")\n",
    "print(\"=\" * 20)\n",
    "\n",
    "# Calcula idade\n",
    "df['Idade'] = (df['Data do Atendimento'] - df['Data de Nascimento']).dt.total_seconds() / (365.25 * 24 * 3600)\n",
    "\n",
    "# Identifica idades absurdas\n",
    "idades_negativas = (df['Idade'] < 0).sum()\n",
    "idades_muito_altas = (df['Idade'] > 120).sum()\n",
    "idades_zeros = (df['Idade'] == 0).sum()\n",
    "\n",
    "print(f\"Idades negativas: {idades_negativas:,}\")\n",
    "print(f\"Idades > 120 anos: {idades_muito_altas:,}\")\n",
    "print(f\"Idades = 0 anos: {idades_zeros:,}\")\n",
    "\n",
    "# Estat√≠sticas de idade\n",
    "print(f\"\\nEstat√≠sticas de idade:\")\n",
    "print(f\"M√≠nima: {df['Idade'].min():.1f} anos\")\n",
    "print(f\"M√°xima: {df['Idade'].max():.1f} anos\")\n",
    "print(f\"M√©dia: {df['Idade'].mean():.1f} anos\")\n",
    "print(f\"Mediana: {df['Idade'].median():.1f} anos\")\n",
    "\n",
    "# Histograma de idades\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(df['Idade'].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribui√ß√£o de Idades', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Idade (anos)')\n",
    "plt.ylabel('Frequ√™ncia')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de valores √∫nicos problem√°ticos\n",
    "print(\"AN√ÅLISE DE VALORES √öNICOS PROBLEM√ÅTICOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Verifica valores √∫nicos em colunas importantes\n",
    "colunas_importantes = ['Sexo', 'Tipo de Unidade', 'Descri√ß√£o do CBO', 'Bairro', 'Munic√≠pio']\n",
    "\n",
    "for col in colunas_importantes:\n",
    "    if col in df.columns:\n",
    "        valores_unicos = df[col].value_counts()\n",
    "        print(f\"\\n{col} - Top 10 valores:\")\n",
    "        print(valores_unicos.head(10))\n",
    "        \n",
    "        # Verifica valores vazios ou suspeitos\n",
    "        valores_vazios = df[col].isnull().sum()\n",
    "        valores_vazio_string = (df[col] == '').sum() if df[col].dtype == 'object' else 0\n",
    "        \n",
    "        if valores_vazios > 0 or valores_vazio_string > 0:\n",
    "            print(f\"  Valores vazios: {valores_vazios + valores_vazio_string:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Processo de Limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma c√≥pia para limpeza\n",
    "df_limpo = df.copy()\n",
    "registros_iniciais = len(df_limpo)\n",
    "\n",
    "print(f\"INICIANDO PROCESSO DE LIMPEZA\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Registros iniciais: {registros_iniciais:,}\")\n",
    "\n",
    "# Lista para registrar as limpezas realizadas\n",
    "limpezas_realizadas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove registros com datas de atendimento inv√°lidas\n",
    "print(\"\\n1. LIMPEZA DE DATAS DE ATENDIMENTO\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "registros_antes = len(df_limpo)\n",
    "\n",
    "# Remove datas nulas\n",
    "df_limpo = df_limpo.dropna(subset=['Data do Atendimento'])\n",
    "datas_nulas_removidas = registros_antes - len(df_limpo)\n",
    "limpezas_realizadas.append(f\"Datas de atendimento nulas: {datas_nulas_removidas:,}\")\n",
    "\n",
    "# Remove datas futuras\n",
    "df_limpo = df_limpo[df_limpo['Data do Atendimento'] <= data_atual]\n",
    "datas_futuras_removidas = registros_antes - len(df_limpo) - datas_nulas_removidas\n",
    "limpezas_realizadas.append(f\"Datas de atendimento futuras: {datas_futuras_removidas:,}\")\n",
    "\n",
    "print(f\"Registros removidos: {datas_nulas_removidas + datas_futuras_removidas:,}\")\n",
    "print(f\"Registros restantes: {len(df_limpo):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Limpeza de datas de nascimento e idades\n",
    "print(\"\\n2. LIMPEZA DE DATAS DE NASCIMENTO E IDADES\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "registros_antes = len(df_limpo)\n",
    "\n",
    "# Remove datas de nascimento muito antigas ou futuras\n",
    "df_limpo = df_limpo[\n",
    "    (df_limpo['Data de Nascimento'] >= data_minima) & \n",
    "    (df_limpo['Data de Nascimento'] <= data_atual)\n",
    "]\n",
    "datas_nascimento_invalidas = registros_antes - len(df_limpo)\n",
    "limpezas_realizadas.append(f\"Datas de nascimento inv√°lidas: {datas_nascimento_invalidas:,}\")\n",
    "\n",
    "# Recalcula idade\n",
    "df_limpo['Idade'] = (df_limpo['Data do Atendimento'] - df_limpo['Data de Nascimento']).dt.total_seconds() / (365.25 * 24 * 3600)\n",
    "\n",
    "# Remove idades absurdas\n",
    "df_limpo = df_limpo[(df_limpo['Idade'] >= 0) & (df_limpo['Idade'] <= 120)]\n",
    "idades_absurdas_removidas = registros_antes - len(df_limpo) - datas_nascimento_invalidas\n",
    "limpezas_realizadas.append(f\"Idades absurdas (negativas ou >120): {idades_absurdas_removidas:,}\")\n",
    "\n",
    "print(f\"Registros removidos: {datas_nascimento_invalidas + idades_absurdas_removidas:,}\")\n",
    "print(f\"Registros restantes: {len(df_limpo):,}\")\n",
    "print(f\"Faixa de idade: {df_limpo['Idade'].min():.1f} a {df_limpo['Idade'].max():.1f} anos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Limpeza de valores vazios em colunas cr√≠ticas\n",
    "print(\"\\n3. LIMPEZA DE VALORES VAZIOS EM COLUNAS CR√çTICAS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "registros_antes = len(df_limpo)\n",
    "\n",
    "# Colunas cr√≠ticas que n√£o podem estar vazias\n",
    "colunas_criticas = ['cod_usuario', 'cod_profissional', 'C√≥digo da Unidade', 'Sexo']\n",
    "colunas_disponiveis = [col for col in colunas_criticas if col in df_limpo.columns]\n",
    "\n",
    "df_limpo = df_limpo.dropna(subset=colunas_disponiveis)\n",
    "valores_criticos_vazios = registros_antes - len(df_limpo)\n",
    "limpezas_realizadas.append(f\"Valores vazios em colunas cr√≠ticas: {valores_criticos_vazios:,}\")\n",
    "\n",
    "print(f\"Colunas cr√≠ticas verificadas: {colunas_disponiveis}\")\n",
    "print(f\"Registros removidos: {valores_criticos_vazios:,}\")\n",
    "print(f\"Registros restantes: {len(df_limpo):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Limpeza de valores inconsistentes\n",
    "print(\"\\n4. LIMPEZA DE VALORES INCONSISTENTES\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "registros_antes = len(df_limpo)\n",
    "\n",
    "# Remove registros com sexo inv√°lido\n",
    "if 'Sexo' in df_limpo.columns:\n",
    "    df_limpo = df_limpo[df_limpo['Sexo'].isin(['F', 'M'])]\n",
    "    sexo_invalido = registros_antes - len(df_limpo)\n",
    "    limpezas_realizadas.append(f\"Sexo inv√°lido: {sexo_invalido:,}\")\n",
    "    registros_antes = len(df_limpo)\n",
    "\n",
    "# Remove registros com tipo de unidade inv√°lido\n",
    "if 'Tipo de Unidade' in df_limpo.columns:\n",
    "    tipos_validos = ['BASICO', 'SIACE']  # Adicione outros tipos v√°lidos se necess√°rio\n",
    "    df_limpo = df_limpo[df_limpo['Tipo de Unidade'].isin(tipos_validos)]\n",
    "    tipo_unidade_invalido = registros_antes - len(df_limpo)\n",
    "    limpezas_realizadas.append(f\"Tipo de unidade inv√°lido: {tipo_unidade_invalido:,}\")\n",
    "    registros_antes = len(df_limpo)\n",
    "\n",
    "print(f\"Registros removidos: {registros_antes - len(df_limpo):,}\")\n",
    "print(f\"Registros restantes: {len(df_limpo):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Remo√ß√£o de duplicatas\n",
    "print(\"\\n5. REMO√á√ÉO DE DUPLICATAS\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "registros_antes = len(df_limpo)\n",
    "\n",
    "# Identifica colunas para verificar duplicatas\n",
    "colunas_duplicata = ['Data do Atendimento', 'cod_usuario', 'cod_profissional', 'C√≥digo da Unidade']\n",
    "colunas_disponiveis = [col for col in colunas_duplicata if col in df_limpo.columns]\n",
    "\n",
    "duplicatas = df_limpo.duplicated(subset=colunas_disponiveis, keep='first').sum()\n",
    "df_limpo = df_limpo.drop_duplicates(subset=colunas_disponiveis, keep='first')\n",
    "\n",
    "limpezas_realizadas.append(f\"Duplicatas: {duplicatas:,}\")\n",
    "\n",
    "print(f\"Duplicatas encontradas: {duplicatas:,}\")\n",
    "print(f\"Registros restantes: {len(df_limpo):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Resumo da Limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo final da limpeza\n",
    "print(\"RESUMO FINAL DA LIMPEZA\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Registros iniciais: {registros_iniciais:,}\")\n",
    "print(f\"Registros finais: {len(df_limpo):,}\")\n",
    "print(f\"Registros removidos: {registros_iniciais - len(df_limpo):,}\")\n",
    "print(f\"Taxa de reten√ß√£o: {len(df_limpo)/registros_iniciais*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nDETALHAMENTO DAS LIMPEZAS:\")\n",
    "print(\"-\" * 30)\n",
    "for limpeza in limpezas_realizadas:\n",
    "    print(f\"‚Ä¢ {limpeza}\")\n",
    "\n",
    "# Gr√°fico de compara√ß√£o\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Gr√°fico de pizza\n",
    "labels = ['Dados Limpos', 'Dados Removidos']\n",
    "sizes = [len(df_limpo), registros_iniciais - len(df_limpo)]\n",
    "colors = ['lightgreen', 'lightcoral']\n",
    "\n",
    "ax1.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "ax1.set_title('Propor√ß√£o de Dados Limpos vs Removidos')\n",
    "\n",
    "# Gr√°fico de barras\n",
    "ax2.bar(['Inicial', 'Final'], [registros_iniciais, len(df_limpo)], \n",
    "        color=['lightblue', 'lightgreen'])\n",
    "ax2.set_title('Quantidade de Registros')\n",
    "ax2.set_ylabel('N√∫mero de Registros')\n",
    "for i, v in enumerate([registros_iniciais, len(df_limpo)]):\n",
    "    ax2.text(i, v + 1000, f'{v:,}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verifica√ß√£o da Qualidade dos Dados Limpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica√ß√£o da qualidade dos dados limpos\n",
    "print(\"VERIFICA√á√ÉO DA QUALIDADE DOS DADOS LIMPOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Estat√≠sticas b√°sicas\n",
    "print(f\"\\nüìä ESTAT√çSTICAS B√ÅSICAS:\")\n",
    "print(f\"Total de registros: {len(df_limpo):,}\")\n",
    "print(f\"Total de colunas: {df_limpo.shape[1]}\")\n",
    "print(f\"Mem√≥ria utilizada: {df_limpo.memory_usage(deep=True).sum() / (1024*1024):.1f} MB\")\n",
    "\n",
    "# Verifica√ß√£o de valores nulos\n",
    "print(f\"\\nüîç VALORES NULOS RESTANTES:\")\n",
    "nulos_restantes = df_limpo.isnull().sum()\n",
    "colunas_com_nulos = nulos_restantes[nulos_restantes > 0]\n",
    "\n",
    "if len(colunas_com_nulos) > 0:\n",
    "    for col, count in colunas_com_nulos.items():\n",
    "        percentual = (count / len(df_limpo)) * 100\n",
    "        print(f\"{col}: {count:,} ({percentual:.1f}%)\")\n",
    "else:\n",
    "    print(\"Nenhuma coluna com valores nulos cr√≠ticos\")\n",
    "\n",
    "# Verifica√ß√£o de idades\n",
    "print(f\"\\nüë• ESTAT√çSTICAS DE IDADE:\")\n",
    "print(f\"M√≠nima: {df_limpo['Idade'].min():.1f} anos\")\n",
    "print(f\"M√°xima: {df_limpo['Idade'].max():.1f} anos\")\n",
    "print(f\"M√©dia: {df_limpo['Idade'].mean():.1f} anos\")\n",
    "print(f\"Mediana: {df_limpo['Idade'].median():.1f} anos\")\n",
    "\n",
    "# Verifica√ß√£o de datas\n",
    "print(f\"\\nüìÖ PER√çODO DOS DADOS:\")\n",
    "print(f\"Data mais antiga: {df_limpo['Data do Atendimento'].min().strftime('%d/%m/%Y')}\")\n",
    "print(f\"Data mais recente: {df_limpo['Data do Atendimento'].max().strftime('%d/%m/%Y')}\")\n",
    "print(f\"Dura√ß√£o: {(df_limpo['Data do Atendimento'].max() - df_limpo['Data do Atendimento'].min()).days} dias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Salvamento dos Dados Limpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva os dados limpos\n",
    "print(\"Salvando dados limpos...\")\n",
    "\n",
    "# Salva em formato CSV\n",
    "arquivo_limpo_csv = 'Dados/dataset_limpo_completo.csv'\n",
    "df_limpo.to_csv(arquivo_limpo_csv, index=False, sep=';', encoding='utf-8')\n",
    "\n",
    "print(f\"‚úì Dataset limpo salvo em: {arquivo_limpo_csv}\")\n",
    "print(f"  - {len(df_limpo):,} registros\")\n",
    "print(f"  - {df_limpo.shape[1]} colunas\")\n",
    "print(f"  - Tamanho do arquivo: {os.path.getsize(arquivo_limpo_csv) / (1024*1024):.1f} MB\")\n",
    "\n",
    "# Tenta salvar em formato pickle\n",
    "try:\n",
    "    arquivo_limpo_pkl = 'Dados/dataset_limpo_completo.pkl'\n",
    "    df_limpo.to_pickle(arquivo_limpo_pkl)\n",
    "    print(f\"‚úì Dataset limpo tamb√©m salvo em pickle: {arquivo_limpo_pkl}\")\n",
    "    print(f"  - Tamanho do arquivo: {os.path.getsize(arquivo_limpo_pkl) / (1024*1024):.1f} MB\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Erro ao salvar em pickle: {e}\")\n",
    "\n",
    "print(\"\\nüéâ LIMPEZA CONCLU√çDA COM SUCESSO!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Documenta√ß√£o da Limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera documenta√ß√£o da limpeza\n",
    "print(\"DOCUMENTA√á√ÉO DA LIMPEZA REALIZADA\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "documentacao = f\"\"\"\n",
    "# Procedimentos de Limpeza - Sistema E-Sa√∫de\n",
    "\n",
    "## Resumo Executivo\n",
    "- **Registros iniciais:** {registros_iniciais:,}\n",
    "- **Registros finais:** {len(df_limpo):,}\n",
    "- **Registros removidos:** {registros_iniciais - len(df_limpo):,}\n",
    "- **Taxa de reten√ß√£o:** {len(df_limpo)/registros_iniciais*100:.1f}%\n",
    "\n",
    "## Procedimentos Realizados\n",
    "\n",
    "### 1. Limpeza de Datas de Atendimento\n",
    "- Removidos registros com datas de atendimento nulas\n",
    "- Removidos registros com datas de atendimento futuras\n",
    "- **Total removido:** {sum([int(limpeza.split(': ')[1].replace(',', '')) for limpeza in limpezas_realizadas if 'atendimento' in limpeza.lower()]):,}\n",
    "\n",
    "### 2. Limpeza de Datas de Nascimento e Idades\n",
    "- Removidos registros com datas de nascimento inv√°lidas (<1900 ou futuras)\n",
    "- Removidos registros com idades absurdas (negativas ou >120 anos)\n",
    "- **Total removido:** {sum([int(limpeza.split(': ')[1].replace(',', '')) for limpeza in limpezas_realizadas if 'nascimento' in limpeza.lower() or 'idade' in limpeza.lower()]):,}\n",
    "\n",
    "### 3. Limpeza de Valores Vazios em Colunas Cr√≠ticas\n",
    "- Removidos registros com valores nulos em: cod_usuario, cod_profissional, C√≥digo da Unidade, Sexo\n",
    "- **Total removido:** {sum([int(limpeza.split(': ')[1].replace(',', '')) for limpeza in limpezas_realizadas if 'cr√≠ticas' in limpeza.lower()]):,}\n",
    "\n",
    "### 4. Limpeza de Valores Inconsistentes\n",
    "- Removidos registros com sexo inv√°lido (apenas F e M aceitos)\n",
    "- Removidos registros com tipo de unidade inv√°lido\n",
    "- **Total removido:** {sum([int(limpeza.split(': ')[1].replace(',', '')) for limpeza in limpezas_realizadas if 'inv√°lido' in limpeza.lower()]):,}\n",
    "\n",
    "### 5. Remo√ß√£o de Duplicatas\n",
    "- Removidas duplicatas baseadas em: Data do Atendimento, cod_usuario, cod_profissional, C√≥digo da Unidade\n",
    "- **Total removido:** {sum([int(limpeza.split(': ')[1].replace(',', '')) for limpeza in limpezas_realizadas if 'duplicata' in limpeza.lower()]):,}\n",
    "\n",
    "## Qualidade Final dos Dados\n",
    "- **Faixa de idade:** {df_limpo['Idade'].min():.1f} a {df_limpo['Idade'].max():.1f} anos\n",
    "- **Per√≠odo:** {df_limpo['Data do Atendimento'].min().strftime('%d/%m/%Y')} a {df_limpo['Data do Atendimento'].max().strftime('%d/%m/%Y')}\n",
    "- **Unidades √∫nicas:** {df_limpo['C√≥digo da Unidade'].nunique():,}\n",
    "- **Profissionais √∫nicos:** {df_limpo['cod_profissional'].nunique():,}\n",
    "- **Pacientes √∫nicos:** {df_limpo['cod_usuario'].nunique():,}\n",
    "\n",
    "## Arquivos Gerados\n",
    "- `dataset_limpo_completo.csv`: Dataset limpo em formato CSV\n",
    "- `dataset_limpo_completo.pkl`: Dataset limpo em formato pickle (se dispon√≠vel)\n",
    "\n",
    "## Observa√ß√µes\n",
    "- A limpeza preservou a integridade dos dados essenciais\n",
    "- Mantida a rastreabilidade dos atendimentos\n",
    "- Removidos apenas registros com problemas claros de qualidade\n",
    "- Dataset final adequado para an√°lises estat√≠sticas e de machine learning\n",
    "\"\"\"\n",
    "\n",
    "print(documentacao)\n",
    "\n",
    "# Salva a documenta√ß√£o\n",
    "with open('Dados/documentacao_limpeza.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(documentacao)\n",
    "\n",
    "print(\"\\n‚úì Documenta√ß√£o salva em: Dados/documentacao_limpeza.md\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
