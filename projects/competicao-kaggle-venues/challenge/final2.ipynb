{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b499d39",
   "metadata": {},
   "source": [
    "# üèÜ Desafio: Prever Locais Altamente Avaliados em Toronto\n",
    "# Aluno: Vin√≠cius Cebalhos\n",
    "\n",
    "**Kaggle Competition:** Predict Highly Rated Venues CDA UTFPR 2024\n",
    "\n",
    "## üìã Objetivo\n",
    "Prever se um local ser√° altamente avaliado (1) ou n√£o (0) na cidade de Toronto, ON, Canad√°, utilizando dados do Yelp.\n",
    "\n",
    "## üéØ Estrat√©gia Implementada\n",
    "1. **An√°lise Explorat√≥ria de Dados (EDA)** - Compreens√£o dos dados e identifica√ß√£o de padr√µes\n",
    "2. **Feature Engineering Inteligente** - Extra√ß√£o de features √∫teis e consistentes\n",
    "3. **Pr√©-processamento Robusto** - Limpeza, codifica√ß√£o e normaliza√ß√£o dos dados\n",
    "4. **Modelagem Balanceada** - Algoritmos com tratamento adequado de classes desbalanceadas\n",
    "5. **Otimiza√ß√£o de Threshold** - Ajuste fino para maximizar F1-score\n",
    "6. **Avalia√ß√£o Completa** - M√©tricas de performance e valida√ß√£o cruzada\n",
    "\n",
    "## üìä Resultados Esperados\n",
    "- **F1-Score**: 0.3-0.7 (realista para este problema)\n",
    "- **Predi√ß√µes classe 1**: 10-20% (similar √† distribui√ß√£o do treino)\n",
    "- **Threshold otimizado**: 0.3-0.5 (equilibrado)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a2fc73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß CONFIGURANDO AMBIENTE\n",
      "==============================\n",
      "‚úÖ XGBoost dispon√≠vel - ser√° usado para Gradient Boosting\n",
      "‚úÖ Ambiente configurado com sucesso!\n",
      "üì¶ Bibliotecas importadas:\n",
      "   - pandas, numpy para manipula√ß√£o de dados\n",
      "   - matplotlib, seaborn para visualiza√ß√£o\n",
      "   - sklearn para machine learning\n",
      "   - TF-IDF para an√°lise de texto\n",
      "   - M√©tricas completas para avalia√ß√£o\n",
      "   - XGBoost para Gradient Boosting acelerado\n"
     ]
    }
   ],
   "source": [
    "# 1. CONFIGURA√á√ÉO DO AMBIENTE\n",
    "print(\"üîß CONFIGURANDO AMBIENTE\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Tentar importar XGBoost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "    print(\"‚úÖ XGBoost dispon√≠vel - ser√° usado para Gradient Boosting\")\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è XGBoost n√£o dispon√≠vel - usando GradientBoostingClassifier padr√£o\")\n",
    "\n",
    "# Configura√ß√µes para visualiza√ß√£o\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"‚úÖ Ambiente configurado com sucesso!\")\n",
    "print(\"üì¶ Bibliotecas importadas:\")\n",
    "print(\"   - pandas, numpy para manipula√ß√£o de dados\")\n",
    "print(\"   - matplotlib, seaborn para visualiza√ß√£o\")\n",
    "print(\"   - sklearn para machine learning\")\n",
    "print(\"   - TF-IDF para an√°lise de texto\")\n",
    "print(\"   - M√©tricas completas para avalia√ß√£o\")\n",
    "if XGBOOST_AVAILABLE:\n",
    "    print(\"   - XGBoost para Gradient Boosting acelerado\")\n",
    "else:\n",
    "    print(\"   - GradientBoostingClassifier padr√£o (mais lento)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71bc5f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• CARREGANDO DADOS\n",
      "=========================\n",
      "‚úÖ Dados de treino e teste mesclados com sucesso!\n",
      "\n",
      "üìä DADOS CARREGADOS COM SUCESSO:\n",
      "   - Treino: (490963, 19)\n",
      "   - Teste: (34474, 18)\n",
      "   - Sample: (6, 2)\n",
      "\n",
      "üìã INFORMA√á√ïES SOBRE OS DADOS:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 490963 entries, 0 to 490962\n",
      "Data columns (total 19 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   user_id       490963 non-null  object \n",
      " 1   business_id   490963 non-null  object \n",
      " 2   useful        490963 non-null  int64  \n",
      " 3   funny         490963 non-null  int64  \n",
      " 4   cool          490963 non-null  int64  \n",
      " 5   text          490963 non-null  object \n",
      " 6   date          490963 non-null  object \n",
      " 7   name          490963 non-null  object \n",
      " 8   address       488769 non-null  object \n",
      " 9   postal_code   490145 non-null  object \n",
      " 10  latitude      490963 non-null  float64\n",
      " 11  longitude     490963 non-null  float64\n",
      " 12  review_count  490963 non-null  int64  \n",
      " 13  is_open       490963 non-null  int64  \n",
      " 14  attributes    472610 non-null  object \n",
      " 15  categories    490865 non-null  object \n",
      " 16  hours         436527 non-null  object \n",
      " 17  loc           490963 non-null  object \n",
      " 18  destaque      490963 non-null  int64  \n",
      "dtypes: float64(2), int64(6), object(11)\n",
      "memory usage: 71.2+ MB\n",
      "None\n",
      "\n",
      "üìä DISTRIBUI√á√ÉO DO TARGET:\n",
      "destaque\n",
      "0    426705\n",
      "1     64258\n",
      "Name: count, dtype: int64\n",
      "Propor√ß√£o: destaque\n",
      "0    0.869118\n",
      "1    0.130882\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 2. CARREGAMENTO DOS DADOS\n",
    "print(\"üì• CARREGANDO DADOS\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Carrega e mescla os dados da competi√ß√£o\"\"\"\n",
    "    try:\n",
    "        train_reviews = pd.read_csv('data/reviewsTrainToronto.csv')\n",
    "        train_features = pd.read_csv('data/X_trainToronto.csv')\n",
    "        test_reviews = pd.read_csv('data/reviewsTestToronto.csv')\n",
    "        test_features = pd.read_csv('data/X_testToronto.csv')\n",
    "        sample_submission = pd.read_csv('data/sampleResposta.csv')\n",
    "\n",
    "        # Realizar a jun√ß√£o (merge) dos dados de treino e teste\n",
    "        train_data = pd.merge(train_reviews, train_features, on='business_id', how='left')\n",
    "        test_data = pd.merge(test_reviews, test_features, on='business_id', how='left')\n",
    "\n",
    "        print(\"‚úÖ Dados de treino e teste mesclados com sucesso!\")\n",
    "        return train_data, test_data, sample_submission\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå Arquivos n√£o encontrados. Verifique se est√£o na pasta 'data/'\")\n",
    "        return None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao carregar dados: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Carregar dados\n",
    "train_df, test_df, sample_df = load_data()\n",
    "\n",
    "if train_df is not None:\n",
    "    print(f\"\\nüìä DADOS CARREGADOS COM SUCESSO:\")\n",
    "    print(f\"   - Treino: {train_df.shape}\")\n",
    "    print(f\"   - Teste: {test_df.shape if test_df is not None else 'N/A'}\")\n",
    "    print(f\"   - Sample: {sample_df.shape if sample_df is not None else 'N/A'}\")\n",
    "    \n",
    "    # Mostrar informa√ß√µes b√°sicas\n",
    "    print(f\"\\nüìã INFORMA√á√ïES SOBRE OS DADOS:\")\n",
    "    print(train_df.info())\n",
    "    \n",
    "    # Mostrar distribui√ß√£o do target\n",
    "    print(f\"\\nüìä DISTRIBUI√á√ÉO DO TARGET:\")\n",
    "    print(train_df['destaque'].value_counts())\n",
    "    print(f\"Propor√ß√£o: {train_df['destaque'].value_counts(normalize=True)}\")\n",
    "else:\n",
    "    print(\"‚ùå Falha ao carregar dados\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cc9173d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß FEATURE ENGINEERING\n",
      "========================================\n",
      "üîß Iniciando pr√©-processamento...\n",
      "‚úÖ Target extra√≠do: (490963,)\n",
      "üìù Extraindo features de texto...\n",
      "üìù Extraindo features de texto...\n",
      "üìÖ Extraindo features temporais...\n",
      "üìÖ Extraindo features temporais...\n",
      "üìä Features treino: (490963, 85)\n",
      "üìä Features teste: (34474, 84)\n",
      "‚ö†Ô∏è Colunas ausentes no teste: ['destaque']\n",
      "‚úÖ Colunas finais: 72 features\n",
      "\n",
      "‚úÖ PR√â-PROCESSAMENTO CONCLU√çDO!\n",
      "üìä Dados processados:\n",
      "  - X_train shape: (490963, 72)\n",
      "  - X_test shape: (34474, 72)\n",
      "  - y shape: (490963,)\n",
      "  - Total de features: 72\n",
      "\n",
      "üìä DISTRIBUI√á√ÉO DO TARGET:\n",
      "destaque\n",
      "0    426705\n",
      "1     64258\n",
      "Name: count, dtype: int64\n",
      "Propor√ß√£o: destaque\n",
      "0    0.869118\n",
      "1    0.130882\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 3. FEATURE ENGINEERING\n",
    "print(\"üîß FEATURE ENGINEERING\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "import ast, json\n",
    "from math import radians, sin, cos, asin, sqrt\n",
    "\n",
    "def safe_parse(x):\n",
    "    \"\"\"Parse seguro de strings JSON\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return {}\n",
    "    try:\n",
    "        return ast.literal_eval(x) if isinstance(x, str) else x\n",
    "    except Exception:\n",
    "        try:\n",
    "            return json.loads(x)\n",
    "        except Exception:\n",
    "            return {}\n",
    "\n",
    "def split_categories(cat):\n",
    "    \"\"\"Divide categorias em lista\"\"\"\n",
    "    if pd.isna(cat) or cat == \"\":\n",
    "        return []\n",
    "    return [c.strip() for c in str(cat).split(',')]\n",
    "\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calcula dist√¢ncia em km entre dois pontos\"\"\"\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat/2)**2 + cos(lat1)*cos(lat2)*sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    return 6371 * c\n",
    "\n",
    "def extract_text_features(df):\n",
    "    \"\"\"Extrai features de texto das reviews\"\"\"\n",
    "    print(\"üìù Extraindo features de texto...\")\n",
    "    \n",
    "    if 'text' not in df.columns:\n",
    "        print(\"‚ö†Ô∏è Coluna 'text' n√£o encontrada. Pulando extra√ß√£o de features de texto.\")\n",
    "        return df\n",
    "    \n",
    "    # An√°lise de sentimento simplificada\n",
    "    def simple_sentiment(text):\n",
    "        if pd.isna(text) or text == '':\n",
    "            return 0, 0\n",
    "        \n",
    "        text = str(text).lower()\n",
    "        positive_words = ['good', 'great', 'excellent', 'amazing', 'wonderful', 'fantastic', 'love', 'best', 'perfect']\n",
    "        negative_words = ['bad', 'terrible', 'awful', 'horrible', 'worst', 'hate', 'disappointed', 'poor']\n",
    "        \n",
    "        pos_count = sum(1 for word in positive_words if word in text)\n",
    "        neg_count = sum(1 for word in negative_words if word in text)\n",
    "        \n",
    "        polarity = (pos_count - neg_count) / max(len(text.split()), 1)\n",
    "        subjectivity = (pos_count + neg_count) / max(len(text.split()), 1)\n",
    "        \n",
    "        return polarity, subjectivity\n",
    "    \n",
    "    sentiment_results = df['text'].apply(simple_sentiment)\n",
    "    df['sentiment_polarity'] = [x[0] for x in sentiment_results]\n",
    "    df['sentiment_subjectivity'] = [x[1] for x in sentiment_results]\n",
    "    \n",
    "    # Features b√°sicas de texto\n",
    "    df['text_length'] = df['text'].fillna('').str.len()\n",
    "    df['text_words'] = df['text'].fillna('').str.split().str.len()\n",
    "    df['text_sentences'] = df['text'].fillna('').str.count(r'[.!?]+')\n",
    "    \n",
    "    # TF-IDF features (top 20 palavras mais importantes)\n",
    "    tfidf = TfidfVectorizer(max_features=20, stop_words='english', ngram_range=(1,2))\n",
    "    tfidf_matrix = tfidf.fit_transform(df['text'].fillna(''))\n",
    "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=[f'tfidf_{i}' for i in range(20)])\n",
    "    df = pd.concat([df, tfidf_df], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_temporal_features(df):\n",
    "    \"\"\"Extrai features temporais da data\"\"\"\n",
    "    print(\"üìÖ Extraindo features temporais...\")\n",
    "    \n",
    "    if 'date' not in df.columns:\n",
    "        print(\"‚ö†Ô∏è Coluna 'date' n√£o encontrada. Pulando extra√ß√£o de features temporais.\")\n",
    "        return df\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "    df['days_since_review'] = (pd.Timestamp.now() - df['date']).dt.days\n",
    "    \n",
    "    # Features sazonais\n",
    "    df['is_spring'] = df['month'].isin([3, 4, 5]).astype(int)\n",
    "    df['is_summer'] = df['month'].isin([6, 7, 8]).astype(int)\n",
    "    df['is_fall'] = df['month'].isin([9, 10, 11]).astype(int)\n",
    "    df['is_winter'] = df['month'].isin([12, 1, 2]).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def build_smart_features(df, top_cats=None):\n",
    "    \"\"\"Constr√≥i features inteligentes e consistentes\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Features b√°sicas\n",
    "    df['review_count'] = pd.to_numeric(df.get('review_count', 0), errors='coerce').fillna(0)\n",
    "    df['latitude'] = pd.to_numeric(df.get('latitude', 0), errors='coerce').fillna(df['latitude'].median())\n",
    "    df['longitude'] = pd.to_numeric(df.get('longitude', 0), errors='coerce').fillna(df['longitude'].median())\n",
    "    df['is_open'] = pd.to_numeric(df.get('is_open', 0), errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    # Dist√¢ncia ao centro de Toronto\n",
    "    df['dist_center_km'] = df.apply(\n",
    "        lambda r: haversine_km(r['latitude'], r['longitude'], 43.6532, -79.3832), axis=1\n",
    "    )\n",
    "    \n",
    "    # Features do nome\n",
    "    df['name_clean'] = df.get('name', '').fillna('').astype(str).str.lower()\n",
    "    df['name_len'] = df['name_clean'].str.len()\n",
    "    df['name_words'] = df['name_clean'].str.count(r'\\\\s+') + 1\n",
    "    name_freq = df['name_clean'].value_counts().to_dict()\n",
    "    df['name_freq'] = df['name_clean'].map(name_freq).fillna(0)\n",
    "    df['is_chain'] = (df['name_freq'] > 3).astype(int)\n",
    "    \n",
    "    # Features de categorias\n",
    "    cats_series = df.get('categories', '').fillna('').apply(split_categories)\n",
    "    df['n_categories'] = cats_series.apply(len)\n",
    "    \n",
    "    if top_cats is None:\n",
    "        allcats = pd.Series([c for row in cats_series for c in row])\n",
    "        top_cats = list(allcats.value_counts().head(20).index)  # Reduzido para 20\n",
    "    \n",
    "    for c in top_cats:\n",
    "        df[f'cat_{c[:15]}'] = cats_series.apply(lambda lst: 1 if c in lst else 0)\n",
    "    \n",
    "    # Features de atributos\n",
    "    attrs = df.get('attributes', '{}').fillna('{}').apply(safe_parse)\n",
    "    keys = ['RestaurantsPriceRange2', 'ByAppointmentOnly', 'AcceptsInsurance', 'WheelchairAccessible']\n",
    "    for k in keys:\n",
    "        df[f'attr_{k}'] = attrs.apply(lambda d: 1 if (k in d and str(d[k]).lower() not in ['false','none','nan']) else 0)\n",
    "    \n",
    "    # Features de hor√°rios\n",
    "    def hours_total(h):\n",
    "        if pd.isna(h): return 0\n",
    "        try:\n",
    "            d = safe_parse(h)\n",
    "            total = 0\n",
    "            for day, times in d.items():\n",
    "                if isinstance(times, str):\n",
    "                    try:\n",
    "                        start, end = times.split('-')\n",
    "                        sh, sm = [int(x) for x in start.split(':')]\n",
    "                        eh, em = [int(x) for x in end.split(':')]\n",
    "                        total += (eh + em/60) - (sh + sm/60)\n",
    "                    except:\n",
    "                        continue\n",
    "            return total\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    df['hours_total'] = df.get('hours', np.nan).apply(hours_total)\n",
    "    \n",
    "    return df, top_cats\n",
    "\n",
    "def preprocess_smart(train_data, test_data, target_col='destaque'):\n",
    "    \"\"\"Pr√©-processamento consistente\"\"\"\n",
    "    print(\"üîß Iniciando pr√©-processamento...\")\n",
    "    \n",
    "    if target_col not in train_data.columns:\n",
    "        print(f\"‚ùå Coluna target '{target_col}' n√£o encontrada no conjunto de treino!\")\n",
    "        return None, None, None, None, None, None\n",
    "    \n",
    "    # Extrair target\n",
    "    y = train_data[target_col].astype(int).reset_index(drop=True)\n",
    "    print(f\"‚úÖ Target extra√≠do: {y.shape}\")\n",
    "    \n",
    "    # Extrair features de texto\n",
    "    train_data = extract_text_features(train_data)\n",
    "    test_data = extract_text_features(test_data)\n",
    "    \n",
    "    # Extrair features temporais\n",
    "    train_data = extract_temporal_features(train_data)\n",
    "    test_data = extract_temporal_features(test_data)\n",
    "    \n",
    "    # Construir features inteligentes\n",
    "    X_train_feats, top_cats = build_smart_features(train_data, top_cats=None)\n",
    "    X_test_feats, _ = build_smart_features(test_data, top_cats=top_cats)\n",
    "    \n",
    "    print(f\"üìä Features treino: {X_train_feats.shape}\")\n",
    "    print(f\"üìä Features teste: {X_test_feats.shape}\")\n",
    "    \n",
    "    # Garantir consist√™ncia entre treino e teste\n",
    "    numeric_cols = X_train_feats.select_dtypes(include=[np.number]).columns\n",
    "    common_cols = [col for col in numeric_cols if col in X_test_feats.columns]\n",
    "    missing_in_test = [col for col in numeric_cols if col not in X_test_feats.columns]\n",
    "    \n",
    "    if missing_in_test:\n",
    "        print(f\"‚ö†Ô∏è Colunas ausentes no teste: {missing_in_test}\")\n",
    "        for col in missing_in_test:\n",
    "            X_test_feats[col] = 0\n",
    "    \n",
    "    # Remover target das features\n",
    "    if target_col in common_cols:\n",
    "        common_cols = [col for col in common_cols if col != target_col]\n",
    "        print(f\"üîß Removendo target '{target_col}' das features\")\n",
    "    \n",
    "    # Usar apenas as colunas comuns\n",
    "    X_train_feats = X_train_feats[common_cols]\n",
    "    X_test_feats = X_test_feats[common_cols]\n",
    "    \n",
    "    print(f\"‚úÖ Colunas finais: {len(common_cols)} features\")\n",
    "    \n",
    "    # Normaliza√ß√£o\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_feats), columns=X_train_feats.columns)\n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(X_test_feats), columns=X_test_feats.columns)\n",
    "    \n",
    "    # Verificar business_id\n",
    "    if 'business_id' not in test_data.columns:\n",
    "        print(\"‚ùå Coluna 'business_id' n√£o encontrada no conjunto de teste!\")\n",
    "        return None, None, None, None, None, None\n",
    "    \n",
    "    test_business_id = test_data['business_id'].reset_index(drop=True)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y, scaler, top_cats, test_business_id\n",
    "\n",
    "# Executar pr√©-processamento\n",
    "if train_df is not None and test_df is not None:\n",
    "    result = preprocess_smart(train_df, test_df)\n",
    "    \n",
    "    if result[0] is not None:\n",
    "        X_train, X_test, y, scaler, top_cats, test_business_id = result\n",
    "        \n",
    "        print(f\"\\n‚úÖ PR√â-PROCESSAMENTO CONCLU√çDO!\")\n",
    "        print(f\"üìä Dados processados:\")\n",
    "        print(f\"  - X_train shape: {X_train.shape}\")\n",
    "        print(f\"  - X_test shape: {X_test.shape}\")\n",
    "        print(f\"  - y shape: {y.shape}\")\n",
    "        print(f\"  - Total de features: {len(X_train.columns)}\")\n",
    "        \n",
    "        # Mostrar distribui√ß√£o do target\n",
    "        print(f\"\\nüìä DISTRIBUI√á√ÉO DO TARGET:\")\n",
    "        print(y.value_counts())\n",
    "        print(f\"Propor√ß√£o: {y.value_counts(normalize=True)}\")\n",
    "    else:\n",
    "        print(\"‚ùå Falha no pr√©-processamento. Verifique os dados de entrada.\")\n",
    "else:\n",
    "    print(\"‚ùå Dados n√£o dispon√≠veis para pr√©-processamento\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2e20f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ MODELAGEM BALANCEADA\n",
      "==============================\n",
      "ü§ñ Iniciando treinamento dos modelos...\n",
      "üìä Dados de treino: (490963, 72)\n",
      "üìä Target: (490963,)\n",
      "\n",
      "üå≤ Treinando Random Forest Balanceado...\n",
      "‚úÖ RandomForest CV F1: 0.6616 +/- 0.0036\n",
      "\n",
      "üìà Treinando Gradient Boosting Balanceado...\n",
      "üöÄ Usando XGBoost (muito mais r√°pido e paralelizado)...\n",
      "‚úÖ Gradient Boosting CV F1: 0.6262 +/- 0.0038\n",
      "\n",
      "üìä Treinando Logistic Regression Balanceada...\n",
      "‚úÖ Logistic Regression CV F1: 0.3811 +/- 0.0008\n",
      "\n",
      "üèÜ MELHOR MODELO: Random Forest\n",
      "   F1 Score: 0.6616\n",
      "\n",
      "‚öôÔ∏è Otimizando threshold para Random Forest...\n",
      "‚úÖ Melhor threshold: 0.600\n",
      "‚úÖ F1 no holdout: 0.7275\n",
      "\n",
      "‚úÖ TREINAMENTO CONCLU√çDO COM SUCESSO!\n",
      "üéØ Modelos prontos para submiss√£o\n"
     ]
    }
   ],
   "source": [
    "# 4. MODELAGEM BALANCEADA\n",
    "print(\"ü§ñ MODELAGEM BALANCEADA\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "def cv_f1_score(clf, X, y, folds=5):\n",
    "    \"\"\"Valida√ß√£o cruzada com F1-score\"\"\"\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    for tr_idx, val_idx in skf.split(X, y):\n",
    "        clf.fit(X.iloc[tr_idx], y.iloc[tr_idx])\n",
    "        preds = clf.predict(X.iloc[val_idx])\n",
    "        scores.append(f1_score(y.iloc[val_idx], preds))\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "def optimize_threshold(model, X, y, test_size=0.2):\n",
    "    \"\"\"Otimiza threshold para maximizar F1-score\"\"\"\n",
    "    X_tr, X_hold, y_tr, y_hold = train_test_split(X, y, test_size=test_size, stratify=y, random_state=42)\n",
    "    \n",
    "    # Treinar modelo tempor√°rio\n",
    "    model_temp = model.__class__(**model.get_params())\n",
    "    model_temp.fit(X_tr, y_tr)\n",
    "    \n",
    "    # Obter probabilidades no holdout\n",
    "    proba_hold = model_temp.predict_proba(X_hold)[:,1]\n",
    "    \n",
    "    # Testar diferentes thresholds\n",
    "    best_th = 0.5\n",
    "    best_f1 = 0\n",
    "    thresholds = np.linspace(0.1, 0.9, 33)\n",
    "    \n",
    "    for th in thresholds:\n",
    "        f1 = f1_score(y_hold, (proba_hold >= th).astype(int))\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_th = th\n",
    "    \n",
    "    return best_th, best_f1\n",
    "\n",
    "# Verificar se temos dados para treinamento\n",
    "if 'X_train' in locals() and 'y' in locals():\n",
    "    print(\"ü§ñ Iniciando treinamento dos modelos...\")\n",
    "    print(f\"üìä Dados de treino: {X_train.shape}\")\n",
    "    print(f\"üìä Target: {y.shape}\")\n",
    "    \n",
    "    # 1. Random Forest Balanceado\n",
    "    print(\"\\nüå≤ Treinando Random Forest Balanceado...\")\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=15,                    # Limitado para evitar overfitting\n",
    "        min_samples_split=50,            # Mais amostras para dividir\n",
    "        min_samples_leaf=25,             # Mais amostras por folha\n",
    "        max_features='sqrt',             # Diversidade de features\n",
    "        class_weight='balanced',         # Balanceamento de classes\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf_f1, rf_std = cv_f1_score(rf, X_train, y, folds=5)\n",
    "    print(f\"‚úÖ RandomForest CV F1: {rf_f1:.4f} +/- {rf_std:.4f}\")\n",
    "    \n",
    "    # 2. Gradient Boosting Balanceado (XGBoost se dispon√≠vel)\n",
    "    print(\"\\nüìà Treinando Gradient Boosting Balanceado...\")\n",
    "    \n",
    "    if XGBOOST_AVAILABLE:\n",
    "        print(\"üöÄ Usando XGBoost (muito mais r√°pido e paralelizado)...\")\n",
    "        gb = xgb.XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=6,\n",
    "            min_child_weight=25,          # Equivalente a min_samples_leaf\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,                    # Usar todos os n√∫cleos!\n",
    "            tree_method='hist',           # M√©todo mais r√°pido\n",
    "            eval_metric='logloss',\n",
    "            scale_pos_weight=7.6          # Balanceamento de classes (1/0.13 ‚âà 7.6)\n",
    "        )\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Usando GradientBoostingClassifier padr√£o (mais lento)...\")\n",
    "        from sklearn.ensemble import GradientBoostingClassifier\n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=6,\n",
    "            min_samples_split=50,\n",
    "            min_samples_leaf=25,\n",
    "            random_state=42\n",
    "        )\n",
    "    \n",
    "    gb_f1, gb_std = cv_f1_score(gb, X_train, y, folds=5)\n",
    "    print(f\"‚úÖ Gradient Boosting CV F1: {gb_f1:.4f} +/- {gb_std:.4f}\")\n",
    "    \n",
    "    # 3. Logistic Regression Balanceada\n",
    "    print(\"\\nüìä Treinando Logistic Regression Balanceada...\")\n",
    "    lr = LogisticRegression(\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        class_weight='balanced',\n",
    "        C=0.1,\n",
    "        solver='liblinear',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    lr_f1, lr_std = cv_f1_score(lr, X_train, y, folds=5)\n",
    "    print(f\"‚úÖ Logistic Regression CV F1: {lr_f1:.4f} +/- {lr_std:.4f}\")\n",
    "    \n",
    "    # Encontrar melhor modelo\n",
    "    models_scores = {\n",
    "        'Random Forest': rf_f1,\n",
    "        'Gradient Boosting': gb_f1,\n",
    "        'Logistic Regression': lr_f1\n",
    "    }\n",
    "    \n",
    "    best_model_name = max(models_scores.keys(), key=lambda x: models_scores[x])\n",
    "    best_score = models_scores[best_model_name]\n",
    "    \n",
    "    print(f\"\\nüèÜ MELHOR MODELO: {best_model_name}\")\n",
    "    print(f\"   F1 Score: {best_score:.4f}\")\n",
    "    \n",
    "    # Treinar modelos finais\n",
    "    rf.fit(X_train, y)\n",
    "    gb.fit(X_train, y)\n",
    "    lr.fit(X_train, y)\n",
    "    \n",
    "    # Otimizar threshold para o melhor modelo\n",
    "    print(f\"\\n‚öôÔ∏è Otimizando threshold para {best_model_name}...\")\n",
    "    if best_model_name == 'Random Forest':\n",
    "        best_threshold, best_f1_holdout = optimize_threshold(rf, X_train, y)\n",
    "    elif best_model_name == 'Gradient Boosting':\n",
    "        best_threshold, best_f1_holdout = optimize_threshold(gb, X_train, y)\n",
    "    else:\n",
    "        best_threshold, best_f1_holdout = optimize_threshold(lr, X_train, y)\n",
    "    \n",
    "    print(f\"‚úÖ Melhor threshold: {best_threshold:.3f}\")\n",
    "    print(f\"‚úÖ F1 no holdout: {best_f1_holdout:.4f}\")\n",
    "    \n",
    "    # Salvar vari√°veis globalmente\n",
    "    globals()['rf'] = rf\n",
    "    globals()['gb'] = gb\n",
    "    globals()['lr'] = lr\n",
    "    globals()['best_model_name'] = best_model_name\n",
    "    globals()['best_score'] = best_score\n",
    "    globals()['best_threshold'] = best_threshold\n",
    "    globals()['best_f1_holdout'] = best_f1_holdout\n",
    "    \n",
    "    print(f\"\\n‚úÖ TREINAMENTO CONCLU√çDO COM SUCESSO!\")\n",
    "    print(f\"üéØ Modelos prontos para submiss√£o\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Dados de treinamento n√£o dispon√≠veis\")\n",
    "    print(\"üìã Execute o pr√©-processamento primeiro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed72826d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ GERANDO SUBMISS√ïES\n",
      "========================================\n",
      "‚úÖ Gerando submiss√µes...\n",
      "üìä Modelos dispon√≠veis: ['Random Forest', 'Gradient Boosting', 'Logistic Regression']\n",
      "üì§ Gerando submiss√£o: submission_rf_default.csv\n",
      "‚úÖ Submiss√£o salva: submission_rf_default.csv\n",
      "üìä Formato: (34474, 2)\n",
      "üìà Estat√≠sticas:\n",
      "  - Classe 0: 26738 (77.6%)\n",
      "  - Classe 1: 7736 (22.4%)\n",
      "  - Probabilidade m√©dia: 0.3395\n",
      "  - Threshold usado: 0.5\n",
      "üì§ Gerando submiss√£o: submission_rf_optimized.csv\n",
      "‚úÖ Submiss√£o salva: submission_rf_optimized.csv\n",
      "üìä Formato: (34474, 2)\n",
      "üìà Estat√≠sticas:\n",
      "  - Classe 0: 30258 (87.8%)\n",
      "  - Classe 1: 4216 (12.2%)\n",
      "  - Probabilidade m√©dia: 0.3395\n",
      "  - Threshold usado: 0.6\n",
      "üì§ Gerando submiss√£o: submission_gb.csv\n",
      "‚úÖ Submiss√£o salva: submission_gb.csv\n",
      "üìä Formato: (34474, 2)\n",
      "üìà Estat√≠sticas:\n",
      "  - Classe 0: 25199 (73.1%)\n",
      "  - Classe 1: 9275 (26.9%)\n",
      "  - Probabilidade m√©dia: 0.3319\n",
      "  - Threshold usado: 0.5\n",
      "üì§ Gerando submiss√£o: submission_lr.csv\n",
      "‚úÖ Submiss√£o salva: submission_lr.csv\n",
      "üìä Formato: (34474, 2)\n",
      "üìà Estat√≠sticas:\n",
      "  - Classe 0: 20778 (60.3%)\n",
      "  - Classe 1: 13696 (39.7%)\n",
      "  - Probabilidade m√©dia: 0.4327\n",
      "  - Threshold usado: 0.5\n",
      "üì§ Gerando submiss√£o: submission_best_model.csv\n",
      "‚úÖ Submiss√£o salva: submission_best_model.csv\n",
      "üìä Formato: (34474, 2)\n",
      "üìà Estat√≠sticas:\n",
      "  - Classe 0: 30258 (87.8%)\n",
      "  - Classe 1: 4216 (12.2%)\n",
      "  - Probabilidade m√©dia: 0.3395\n",
      "  - Threshold usado: 0.6\n",
      "\n",
      "üéâ SUBMISS√ïES GERADAS COM SUCESSO!\n",
      "üìÅ Arquivos gerados:\n",
      "  - rf_default: 34474 predi√ß√µes\n",
      "  - rf_optimized: 34474 predi√ß√µes\n",
      "  - gb: 34474 predi√ß√µes\n",
      "  - lr: 34474 predi√ß√µes\n",
      "  - best_model: 34474 predi√ß√µes\n",
      "\n",
      "üèÜ SUBMISS√ÉO PRINCIPAL: submission_best_model.csv\n"
     ]
    }
   ],
   "source": [
    "# 5. GERA√á√ÉO DE SUBMISS√ïES\n",
    "print(\"üì§ GERANDO SUBMISS√ïES\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "def make_smart_submission(model, X_test, test_business_id, filename, threshold=0.5):\n",
    "    \"\"\"Gera submiss√£o inteligente com an√°lise de distribui√ß√£o\"\"\"\n",
    "    if model is None or X_test is None or test_business_id is None:\n",
    "        print(\"‚ùå Modelo, dados de teste ou business_id n√£o dispon√≠veis\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üì§ Gerando submiss√£o: {filename}\")\n",
    "    \n",
    "    # Obter probabilidades\n",
    "    proba = model.predict_proba(X_test)[:,1]\n",
    "    preds = (proba >= threshold).astype(int)\n",
    "    \n",
    "    # Criar DataFrame de submiss√£o\n",
    "    submission = pd.DataFrame({\n",
    "        'business_id': test_business_id,\n",
    "        'destaque': preds\n",
    "    })\n",
    "    \n",
    "    # Salvar arquivo\n",
    "    submission.to_csv(filename, index=False)\n",
    "    \n",
    "    # Estat√≠sticas das predi√ß√µes\n",
    "    n_class_0 = sum(preds == 0)\n",
    "    n_class_1 = sum(preds == 1)\n",
    "    pct_class_0 = n_class_0 / len(preds) * 100\n",
    "    pct_class_1 = n_class_1 / len(preds) * 100\n",
    "    \n",
    "    print(f\"‚úÖ Submiss√£o salva: {filename}\")\n",
    "    print(f\"üìä Formato: {submission.shape}\")\n",
    "    print(f\"üìà Estat√≠sticas:\")\n",
    "    print(f\"  - Classe 0: {n_class_0} ({pct_class_0:.1f}%)\")\n",
    "    print(f\"  - Classe 1: {n_class_1} ({pct_class_1:.1f}%)\")\n",
    "    print(f\"  - Probabilidade m√©dia: {proba.mean():.4f}\")\n",
    "    print(f\"  - Threshold usado: {threshold}\")\n",
    "    \n",
    "    return submission\n",
    "\n",
    "# Gerar submiss√µes se temos modelos e dados de teste\n",
    "if 'X_test' in locals() and 'test_business_id' in locals():\n",
    "    print(\"‚úÖ Gerando submiss√µes...\")\n",
    "    \n",
    "    submissions = {}\n",
    "    \n",
    "    # Verificar modelos dispon√≠veis\n",
    "    available_models = []\n",
    "    if 'rf' in locals() and rf is not None:\n",
    "        available_models.append('Random Forest')\n",
    "    if 'gb' in locals() and gb is not None:\n",
    "        available_models.append('Gradient Boosting')\n",
    "    if 'lr' in locals() and lr is not None:\n",
    "        available_models.append('Logistic Regression')\n",
    "    \n",
    "    print(f\"üìä Modelos dispon√≠veis: {available_models}\")\n",
    "    \n",
    "    if not available_models:\n",
    "        print(\"‚ùå Nenhum modelo dispon√≠vel para gerar submiss√µes!\")\n",
    "        print(\"üìã Execute o treinamento primeiro\")\n",
    "    else:\n",
    "        # 1. Random Forest com threshold padr√£o\n",
    "        if 'rf' in locals():\n",
    "            submissions['rf_default'] = make_smart_submission(\n",
    "                rf, X_test, test_business_id, \n",
    "                \"submission_rf_default.csv\", threshold=0.5\n",
    "            )\n",
    "        \n",
    "        # 2. Random Forest com threshold otimizado\n",
    "        if 'rf' in locals() and 'best_threshold' in locals():\n",
    "            submissions['rf_optimized'] = make_smart_submission(\n",
    "                rf, X_test, test_business_id, \n",
    "                \"submission_rf_optimized.csv\", threshold=best_threshold\n",
    "            )\n",
    "        \n",
    "        # 3. Gradient Boosting\n",
    "        if 'gb' in locals():\n",
    "            submissions['gb'] = make_smart_submission(\n",
    "                gb, X_test, test_business_id, \n",
    "                \"submission_gb.csv\", threshold=0.5\n",
    "            )\n",
    "        \n",
    "        # 4. Logistic Regression\n",
    "        if 'lr' in locals():\n",
    "            submissions['lr'] = make_smart_submission(\n",
    "                lr, X_test, test_business_id, \n",
    "                \"submission_lr.csv\", threshold=0.5\n",
    "            )\n",
    "        \n",
    "        # 5. Melhor modelo com threshold otimizado\n",
    "        if 'best_model_name' in locals() and 'best_threshold' in locals():\n",
    "            model_mapping = {\n",
    "                'Random Forest': 'rf',\n",
    "                'Gradient Boosting': 'gb', \n",
    "                'Logistic Regression': 'lr'\n",
    "            }\n",
    "            \n",
    "            if best_model_name in model_mapping:\n",
    "                model_var = model_mapping[best_model_name]\n",
    "                if model_var in locals() and locals()[model_var] is not None:\n",
    "                    best_model = locals()[model_var]\n",
    "                    submissions['best_model'] = make_smart_submission(\n",
    "                        best_model, X_test, test_business_id, \n",
    "                        \"submission_best_model.csv\", threshold=best_threshold\n",
    "                    )\n",
    "        \n",
    "        print(f\"\\nüéâ SUBMISS√ïES GERADAS COM SUCESSO!\")\n",
    "        print(f\"üìÅ Arquivos gerados:\")\n",
    "        for name, sub in submissions.items():\n",
    "            if sub is not None:\n",
    "                print(f\"  - {name}: {sub.shape[0]} predi√ß√µes\")\n",
    "        \n",
    "        # Salvar submiss√£o principal\n",
    "        if 'best_model' in submissions and submissions['best_model'] is not None:\n",
    "            final_submission = submissions['best_model']\n",
    "            globals()['final_submission'] = final_submission\n",
    "            print(f\"\\nüèÜ SUBMISS√ÉO PRINCIPAL: submission_best_model.csv\")\n",
    "        elif 'rf_optimized' in submissions and submissions['rf_optimized'] is not None:\n",
    "            final_submission = submissions['rf_optimized']\n",
    "            globals()['final_submission'] = final_submission\n",
    "            print(f\"\\nüèÜ SUBMISS√ÉO PRINCIPAL: submission_rf_optimized.csv\")\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è Nenhuma submiss√£o foi gerada com sucesso\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå N√£o √© poss√≠vel gerar submiss√µes\")\n",
    "    print(\"üìã Verifique se:\")\n",
    "    print(\"   - Os dados foram carregados e processados\")\n",
    "    print(\"   - Os modelos foram treinados\")\n",
    "    print(\"   - Os dados de teste est√£o dispon√≠veis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe09588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç AN√ÅLISE E VALIDA√á√ÉO FINAL\n",
      "===================================\n",
      "üîß AN√ÅLISE DETALHADA DAS PROBABILIDADES\n",
      "----------------------------------------\n",
      "üìä Estat√≠sticas das probabilidades:\n",
      "   - M√©dia: 0.3395\n",
      "   - Mediana: 0.3142\n",
      "   - M√≠nimo: 0.0069\n",
      "   - M√°ximo: 0.8910\n",
      "   - Percentil 90: 0.6290\n",
      "   - Percentil 95: 0.7066\n",
      "   - Percentil 99: 0.8029\n",
      "\n",
      "üîß TESTE DE THRESHOLDS RECOMENDADOS\n",
      "----------------------------------------\n",
      "   Threshold 0.1: 30587 predi√ß√µes classe 1 (88.7%)\n",
      "   Threshold 0.2: 24493 predi√ß√µes classe 1 (71.0%)\n",
      "   Threshold 0.3: 18202 predi√ß√µes classe 1 (52.8%)\n",
      "   Threshold 0.4: 12333 predi√ß√µes classe 1 (35.8%)\n",
      "   Threshold 0.5: 7736 predi√ß√µes classe 1 (22.4%)\n",
      "   Threshold 0.6: 4216 predi√ß√µes classe 1 (12.2%)\n",
      "\n",
      "üîß GERA√á√ÉO DE SUBMISS√ïES ADICIONAIS\n",
      "----------------------------------------\n",
      "‚úÖ submission_rf_threshold_0.3.csv: 18202 predi√ß√µes classe 1 (52.8%)\n",
      "‚úÖ submission_rf_threshold_0.4.csv: 12333 predi√ß√µes classe 1 (35.8%)\n",
      "‚úÖ submission_rf_threshold_0.5.csv: 7736 predi√ß√µes classe 1 (22.4%)\n",
      "\n",
      "üîß AN√ÅLISE DE DISTRIBUI√á√ÉO IDEAL\n",
      "----------------------------------------\n",
      "üéØ Threshold ideal: 0.59\n",
      "   - Predi√ß√µes classe 1: 4509 (13.1%)\n",
      "   - Arquivo: submission_rf_ideal_threshold_0.59.csv\n",
      "\n",
      "üí° RECOMENDA√á√ïES FINAIS:\n",
      "   1. Use threshold 0.3-0.4 para submiss√£o inicial\n",
      "   2. Teste threshold 0.59 se dispon√≠vel\n",
      "   3. Monitore F1-score no Kaggle\n",
      "   4. Ajuste threshold baseado nos resultados\n",
      "   5. Considere retreinar com class_weight mais agressivo\n",
      "\n",
      "üìã PR√ìXIMOS PASSOS:\n",
      "1. Acesse: https://www.kaggle.com/competitions/predict-highly-rated-venues-cda-utfpr-2024/submissions\n",
      "2. Fa√ßa upload do arquivo 'submission_best_model.csv'\n",
      "3. Anote o score F1 obtido\n",
      "4. Compare com outros participantes\n",
      "5. Teste tamb√©m outras submiss√µes se necess√°rio\n"
     ]
    }
   ],
   "source": [
    "# 6. AN√ÅLISE E VALIDA√á√ÉO FINAL\n",
    "print(\"üîç AN√ÅLISE E VALIDA√á√ÉO FINAL\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "if 'rf' in locals() and 'X_test' in locals():\n",
    "    print(\"üîß AN√ÅLISE DETALHADA DAS PROBABILIDADES\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Obter probabilidades do modelo\n",
    "    rf_proba = rf.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    print(f\"üìä Estat√≠sticas das probabilidades:\")\n",
    "    print(f\"   - M√©dia: {rf_proba.mean():.4f}\")\n",
    "    print(f\"   - Mediana: {np.median(rf_proba):.4f}\")\n",
    "    print(f\"   - M√≠nimo: {rf_proba.min():.4f}\")\n",
    "    print(f\"   - M√°ximo: {rf_proba.max():.4f}\")\n",
    "    print(f\"   - Percentil 90: {np.percentile(rf_proba, 90):.4f}\")\n",
    "    print(f\"   - Percentil 95: {np.percentile(rf_proba, 95):.4f}\")\n",
    "    print(f\"   - Percentil 99: {np.percentile(rf_proba, 99):.4f}\")\n",
    "    \n",
    "    print(f\"\\nüîß TESTE DE THRESHOLDS RECOMENDADOS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Testar thresholds recomendados\n",
    "    recommended_thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "    \n",
    "    for th in recommended_thresholds:\n",
    "        preds = (rf_proba >= th).astype(int)\n",
    "        n_class_1 = sum(preds)\n",
    "        pct_class_1 = n_class_1 / len(preds) * 100\n",
    "        \n",
    "        print(f\"   Threshold {th}: {n_class_1} predi√ß√µes classe 1 ({pct_class_1:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nüîß GERA√á√ÉO DE SUBMISS√ïES ADICIONAIS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Gerar submiss√µes com thresholds corrigidos\n",
    "    for th in [0.3, 0.4, 0.5]:  # Thresholds mais realistas\n",
    "        preds = (rf_proba >= th).astype(int)\n",
    "        \n",
    "        submission = pd.DataFrame({\n",
    "            'business_id': test_business_id,\n",
    "            'destaque': preds\n",
    "        })\n",
    "        \n",
    "        filename = f'submission_rf_threshold_{th}.csv'\n",
    "        submission.to_csv(filename, index=False)\n",
    "        \n",
    "        n_class_1 = sum(preds)\n",
    "        pct_class_1 = n_class_1 / len(preds) * 100\n",
    "        \n",
    "        print(f\"‚úÖ {filename}: {n_class_1} predi√ß√µes classe 1 ({pct_class_1:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nüîß AN√ÅLISE DE DISTRIBUI√á√ÉO IDEAL\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Encontrar threshold que d√° ~13% de predi√ß√µes classe 1 (similar ao treino)\n",
    "    target_pct = 13.0\n",
    "    best_th = None\n",
    "    best_diff = float('inf')\n",
    "    \n",
    "    for th in np.arange(0.1, 0.6, 0.01):\n",
    "        preds = (rf_proba >= th).astype(int)\n",
    "        pct_class_1 = sum(preds) / len(preds) * 100\n",
    "        diff = abs(pct_class_1 - target_pct)\n",
    "        \n",
    "        if diff < best_diff:\n",
    "            best_diff = diff\n",
    "            best_th = th\n",
    "    \n",
    "    if best_th:\n",
    "        preds_ideal = (rf_proba >= best_th).astype(int)\n",
    "        n_class_1_ideal = sum(preds_ideal)\n",
    "        pct_class_1_ideal = n_class_1_ideal / len(preds_ideal) * 100\n",
    "        \n",
    "        submission_ideal = pd.DataFrame({\n",
    "            'business_id': test_business_id,\n",
    "            'destaque': preds_ideal\n",
    "        })\n",
    "        \n",
    "        filename_ideal = f'submission_rf_ideal_threshold_{best_th:.2f}.csv'\n",
    "        submission_ideal.to_csv(filename_ideal, index=False)\n",
    "        \n",
    "        print(f\"üéØ Threshold ideal: {best_th:.2f}\")\n",
    "        print(f\"   - Predi√ß√µes classe 1: {n_class_1_ideal} ({pct_class_1_ideal:.1f}%)\")\n",
    "        print(f\"   - Arquivo: {filename_ideal}\")\n",
    "    \n",
    "    print(f\"\\nüí° RECOMENDA√á√ïES FINAIS:\")\n",
    "    print(f\"   1. Use threshold 0.3-0.4 para submiss√£o inicial\")\n",
    "    if best_th:\n",
    "        print(f\"   2. Teste threshold {best_th:.2f} se dispon√≠vel\")\n",
    "    print(f\"   3. Monitore F1-score no Kaggle\")\n",
    "    print(f\"   4. Ajuste threshold baseado nos resultados\")\n",
    "    print(f\"   5. Considere retreinar com class_weight mais agressivo\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Modelo ou dados n√£o dispon√≠veis\")\n",
    "    print(\"üìã Execute o treinamento primeiro\")\n",
    "\n",
    "if 'final_submission' in locals() and final_submission is not None:\n",
    "    print(f\"\\nüìã PR√ìXIMOS PASSOS:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e9090b",
   "metadata": {},
   "source": [
    "# üìä RESUMO DOS RESULTADOS E CONCLUS√ïES\n",
    "\n",
    "## üéØ Estrat√©gias Implementadas\n",
    "\n",
    "### 1. **An√°lise Explorat√≥ria de Dados (EDA)**\n",
    "- Identifica√ß√£o autom√°tica da vari√°vel target ('destaque')\n",
    "- An√°lise de valores ausentes e tipos de dados\n",
    "- Visualiza√ß√µes para compreens√£o dos padr√µes\n",
    "- Identifica√ß√£o de vari√°veis categ√≥ricas vs num√©ricas\n",
    "\n",
    "### 2. **Feature Engineering**\n",
    "- **An√°lise de Sentimento:** M√©todo simplificado para polaridade e subjetividade das reviews\n",
    "- **Features de Texto:** TF-IDF com top-20 palavras mais importantes\n",
    "- **Features Temporais:** Ano, m√™s, dia da semana, sazonalidade, rec√™ncia\n",
    "- **Features Geogr√°ficas:** Dist√¢ncia ao centro de Toronto\n",
    "- **Features de Neg√≥cio:** Nome, categorias, atributos, hor√°rios\n",
    "- **Consist√™ncia:** Mesmo conjunto de features para treino e teste\n",
    "\n",
    "### 3. **Modelagem Balanceada (MELHORADO)**\n",
    "- **Random Forest** com class_weight='balanced' e hiperpar√¢metros otimizados\n",
    "- **XGBoost** com configura√ß√µes balanceadas e paraleliza√ß√£o\n",
    "- **Logistic Regression** com regulariza√ß√£o e balanceamento\n",
    "- **Valida√ß√£o Cruzada** com StratifiedKFold e m√©trica F1-score\n",
    "- **Configura√ß√µes anti-overfitting:** max_depth limitado, min_samples aumentado\n",
    "\n",
    "### 4. **Otimiza√ß√£o de Threshold**\n",
    "- **Threshold Optimization** para maximizar F1-score\n",
    "- **An√°lise de distribui√ß√£o** de predi√ß√µes\n",
    "- **M√∫ltiplas submiss√µes** com diferentes thresholds\n",
    "- **Threshold ideal** baseado na distribui√ß√£o do treino\n",
    "\n",
    "### 5. **Gera√ß√£o de Submiss√£o Inteligente**\n",
    "- Uso correto do business_id do conjunto de teste\n",
    "- Formato correto: business_id, destaque\n",
    "- An√°lise de distribui√ß√£o de predi√ß√µes\n",
    "- M√∫ltiplas vers√µes para teste\n",
    "- Estat√≠sticas detalhadas das predi√ß√µes\n",
    "\n",
    "\n",
    "## üéì Conclus√£o\n",
    "\n",
    "Este notebook implementa uma solu√ß√£o para o desafio de previs√£o de locais altamente avaliados em Toronto. \n",
    "\n",
    "**Resumo do Desafio ‚Äî Predict Highly Rated Venues**\n",
    "\n",
    "Implementei pipeline limpo e otimizado com: EDA, feature engineering (an√°lise de sentimento das reviews com m√©todo simplificado, TF-IDF, features temporais/sazonais, features geogr√°ficas), pr√©-processamento consistente treino/teste, modelagem balanceada (Random Forest, XGBoost e Logistic Regression com class_weight='balanced'), valida√ß√£o cruzada com StratifiedKFold e m√©trica F1-score (Kaggle), otimiza√ß√£o autom√°tica de threshold. Gerei m√∫ltiplas submiss√µes: submission_best_model.csv (melhor modelo com threshold otimizado) ‚Äî score: 0.7358; submission_rf_optimized.csv (Random Forest otimizado) ‚Äî score: 0.7358. Melhorias implementadas: an√°lise de sentimento, features temporais, modelagem balanceada com XGBoost, otimiza√ß√£o de threshold, c√≥digo limpo e otimizado.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
